{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Practica 2 Machine Learning"
      ],
      "metadata": {
        "id": "5BGFuTvn240f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Informacion General Del Alumno\n",
        "\n",
        "Alumno : Garcia de Arcos Jose Angel Eduardo\n",
        "\n",
        "Clase : Aprendizaje de Maquina 5AM1\n",
        "\n",
        "Universidad : Escuela Superior de Computo - IPN"
      ],
      "metadata": {
        "id": "TsulZvya21sR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Informacion general de la practica\n",
        "Utilice el dataset weatherAUS.csv para realizar lo siguiente:\n",
        "1. Cargue el dataset en un dataframe de pandas\n",
        "2. Separe el dataset en un conjunto de entrenamiento (80%) y de prueba (20%) asegurándose de  mezclar los datos\n",
        "3. Usando el conjunto de entrenamiento cree los siguientes conjuntos de validación mediante  validación cruzada\n",
        "\n",
        "  • 3 pliegues\n",
        "\n",
        "  • 5 pliegues\n",
        "\n",
        "  • 10 pliegues\n",
        "\n",
        "4. Cree las clases necesarias para almacenar los conjuntos de datos creados\n",
        "5. Guarde en archivos csv los datos y etiquetas de cada conjunto de validación\n",
        "\n",
        "  • data_validation_train_<num_pliegues>_<pliegue>.csv\n",
        "\n",
        "  • target_validation_train_<num_pliegues>_<pliegue>.csv\n",
        "\n",
        "  • data_test_<num_pliegues>_<pliegue>.csv\n",
        "\n",
        "  • target_test_<num_pliegues>_<pliegue>.csv\n",
        "\n",
        "6. Guarde en archivos csv los datos y etiquetas del conjunto de prueba\n",
        "\n",
        "  • data_test.csv\n",
        "\n",
        "  • target_test.csv\n",
        "\n",
        "7. Guarde en un archivo pkl el objeto que almacena los conjuntos de datos creado"
      ],
      "metadata": {
        "id": "NRva8Ll82_-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCTtzID02rjE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class validation_set:\n",
        "\tdef __init__(self, X_train, y_train, X_test, y_test):\n",
        "\t\tself.X_train = X_train\n",
        "\t\tself.y_train = y_train\n",
        "\t\tself.X_test = X_test\n",
        "\t\tself.y_test = y_test\n",
        "\n",
        "class test_set:\n",
        "\tdef __init__(self, X_test, y_test):\n",
        "\t\tself.X_test = X_test\n",
        "\t\tself.y_test = y_test\n",
        "\n",
        "class data_set:\n",
        "\tdef __init__(self, validation_set, test_set):\n",
        "\t\tself.validation_set = validation_set\n",
        "\t\tself.test_set = test_set"
      ],
      "metadata": {
        "id": "yW0MugJj5PiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generador3Pliegues (NombreArchivo):\n",
        "  pd.options.display.max_colwidth = 200\n",
        "  df = pd.read_csv(NombreArchivo, sep=',', engine='python')\n",
        "  X = df.drop(columns=['RainTomorrow'],axis = 1).values\n",
        "  y = df['RainTomorrow'].values \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True)\n",
        "  validation_sets = []\n",
        "  kf = KFold(n_splits=3) #Modificar Parametro para obtener los demas pliegues\n",
        "  c=0\n",
        "  for train_index, test_index in kf.split(X_train):\n",
        "    c=c+1\n",
        "    X_train_v, X_test_v = X_train[train_index], X_train[test_index]\n",
        "    y_train_v, y_test_v = y_train[train_index], y_train[test_index]\n",
        "    #Agrega el pliegue creado a la lista\n",
        "    validation_sets.append(validation_set(X_train_v, y_train_v, X_test_v, y_test_v))\n",
        "  my_test_set = test_set(X_test, y_test)\n",
        "  my_data_set = data_set(validation_sets, my_test_set) \n",
        "  return (my_data_set)"
      ],
      "metadata": {
        "id": "q8J-edOw5TXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ =='__main__':\n",
        "  my_data_set = generador3Pliegues(\"/content/weatherAUS.csv\")\n",
        "\n",
        "  np.savetxt(\"data_test.csv\", my_data_set.test_set.X_test ,delimiter=\",\",fmt=\"%s\", header=\"x\")\n",
        "  np.savetxt(\"target_test.csv\",my_data_set.test_set.y_test ,delimiter=\",\",fmt=\"%s\",header=\"y\")\n",
        "  i = 1\n",
        "  for val_set in my_data_set.validation_set:\n",
        "    np.savetxt(\"Data_Validation_Train_3Pliegues\" + str(i) + \".csv\", val_set.X_train, delimiter=\",\", fmt=\"%s\",\n",
        "           header=\"Date , Location , MinTemp, MaxTemp, Rainfall , Evaporation, Sunshine , WindGustDir , WindGustSpeed , WindDir9am , WindDir3pm , WindSpeed9am , WindSpeed3pm , Humidity9am ,Humidity3pm, Pressure9am, Pressure3pm , Cloud9am , Cloud3pm, Temp9am , Temp3pm , RainToday\", comments=\"\")\n",
        "    np.savetxt(\"data_test_\" + str(i) + \".csv\", val_set.X_test, delimiter=\",\", fmt=\"%s\",\n",
        "           header=\"Date , Location , MinTemp, MaxTemp, Rainfall , Evaporation, Sunshine , WindGustDir , WindGustSpeed , WindDir9am , WindDir3pm , WindSpeed9am , WindSpeed3pm , Humidity9am ,Humidity3pm, Pressure9am, Pressure3pm , Cloud9am , Cloud3pm, Temp9am , Temp3pm  ,RainToday\", comments=\"\")\n",
        "    np.savetxt(\"target_Validation_train\" + str(i) + \".csv\", val_set.y_train, delimiter=\",\", fmt=\"%s\",\n",
        "           header=\" RainTommorrow\", comments=\"\")\n",
        "    np.savetxt(\"target_test_\" + str(i) + \".csv\", val_set.y_test, delimiter=\",\", fmt=\"%s\",\n",
        "           header=\" RainTommorrow\", comments=\"\")\n",
        "    i = i + 1\n",
        "  \n",
        "  dataset_file = open ('dataset.pkl','wb')\n",
        "  pickle.dump(my_data_set, dataset_file)\n",
        "  dataset_file.close()\n",
        "  dataset_file = open ('dataset.pkl','rb')\n",
        "  my_data_set_pickle = pickle.load(dataset_file)\n",
        "  \n",
        " \n"
      ],
      "metadata": {
        "id": "HeRnZJmM7qlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_pJxILL9Tu6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}